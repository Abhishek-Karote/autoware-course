# Lecture 04: Platform (ECUs, RTOS, and DDS)
[![Autoware.Auto badge](https://img.shields.io/badge/Autoware-Auto-orange.svg)](https://www.autoware.auto)

This lecture is provided by [Stephane Strahm](https://www.linkedin.com/in/stephanestrahm/) (Product Manager at Kalray) and by [Angelo Corsaro](https://www.linkedin.com/in/corsaro/) (AD-Link CTO). The lecture is available in YouTube:

[![Lecture video](https://img.youtube.com/vi/IyycN6ldsIs/0.jpg)](https://www.youtube.com/watch?v=IyycN6ldsIs&list=PLL57Sz4fhxLpCXgN0lvCF7aHAlRA5FoFr&index=4)

The target will be to cover the underlying technologies under the systems that run Autoware.Auto and ROS 2. The **first part** will include three topics: (1) Electronic Control Units (ECUs), (2) Real Time Operating Systems (RTOS), and (3) design and optimization criterias. Next, the **second part** will cover ROS 2's middleware, Data Distribution Service (DDS).

The provided PDFs can be found in the Apex.AI's [autowareclass2020 repository](https://gitlab.com/ApexAI/autowareclass2020/-/blob/master/lectures/04_Platform), in GitLab. There is one for the [first](https://gitlab.com/ApexAI/autowareclass2020/-/blob/master/lectures/04_Platform/ECUandRTOS.pdf) and another for the [second](https://gitlab.com/ApexAI/autowareclass2020/-/blob/master/lectures/04_Platform/DDSExplained.pdf) part of the lecture.



## [4.1. Electronic Control Units (ECUs)](https://youtu.be/IyycN6ldsIs?t=75)
In a [SAE Level 2](https://www.sae.org/news/2019/01/sae-updates-j3016-automated-driving-graphic) vehicle, more than 80 ECUs can be found, destinated to control systems such as the audio, video, navigation, motor control, Advanced Driving Assitance System (ADAS), Autonomous Driving (AD), etc. This number has been increased as new features and technologies were introduced in vehicles, which increased both the complexity of the system and the concerns about the safety. In this lecture, we will focus on ADAS and AD ECUs. The ADAS one will assist the driver monitoring its speed, using sensors during parking, alert of the presence of radars or other vehicles nearby, etc. All these things while the driver remain in control of the vehicle. The AD ECU will make the vehicle able to be driven by itself.

The **ADAS and AD ECU functions** can be classified in four different groups:

- **Sensors** such as cameras, GPS, RADAR or LIDAR. This module is in charge of gathering data about the vehicle's environment. This data will be forwarded to the perception module. By combining data from these sensors, a more reliable and robust system is achieved.
- **Perception**: Its task is to process the data obtained with the sensors to generate higher-level information. Some ways of doing so is using localization, tracking, detection, classification and/or segmentation techniques.
- **Planning**: With the knowledge generated by the perception module, the planning one will decide which behaviour to perform and compute a trajectory that implements it. It is also in charge of planning long/global routes and usually tries to predict the behaviour of the other elements around the vehicle to plan safe actions.
- **Control**: Once knowing where and how the vehicle must move, the control module will manage the engine, steering wheel, brakes and other systems to reach the targets in optimal ways.


### [4.1.1. Automotive ECUs](https://youtu.be/IyycN6ldsIs?t=655)
Automotive ECUs will require different **components**. The main will be:

- **Inputs and outputs** to connect the sensors and actuators so that they can be used by the ECU.
- **Application processors**: To fuse the data from the sensors and perform the planning and control. Specific processors may be needed to work with specific types of data, such as Digital Singal Processors (DSPs) for signals, others for visual information, etc. They are powerful components, both x86 and ARM are used.
- **Accellerator units**: Some heavy computation may be needed for, for examples, running CNNs or heavy mathematical algorithms. Today, those heavy calculations are usually done solved with GPUs.
- **Safety processors**: Given how critical the automotive applications are, it is essential to have fully reliable systems. This is why there are processors used exclusively for safety-related tasks, which are monitoring the overall system. Appart of this, the [ISO 26262](https://www.iso.org/obp/ui/#iso:std:iso:26262:-2:ed-2:v1:en) defines development and verification processes that must be followed to ensure the required safety level specified by the [Automotive Safety Integrity Level (ASIL)](https://www.synopsys.com/automotive/what-is-asil.html) levels.

The big ammount of required functions and the extense history and evolution has left us with a large spectrum of boards and chips. A few of them are the [Kalray products](https://www.kalrayinc.com/products/), the NXP's [BlueBox](https://www.nxp.com/design/development-boards/automotive-development-platforms/nxp-bluebox-autonomous-driving-development-platform:BLBX) and [S32G](https://www.nxp.com/products/processors-and-microcontrollers/arm-processors/s32-automotive-platform/s32g-processors-for-vehicle-networking:S32G274A)], the [Tesla's AD board](https://www.theverge.com/2019/4/22/18511594/tesla-new-self-driving-chip-is-here-and-this-is-your-best-look-yet), the [Infineron](https://www.infineon.com/cms/en/) safety processors or the [NVIDIA options](https://www.nvidia.com/en-us/self-driving-cars). There are many options for production, pre-production and development that are constantly evolving thanks to the revolutions introduced by tier 1 or Original Equipment Manufacturers (OEMs).


### [4.1.2. Supporting Software for ECUs](https://youtu.be/IyycN6ldsIs?t=975)
To have all these functions runing, abstraction levels are adopted in the software of the ECUs. These levels will be:

- **Hardware**: Composed by application and safety processors and accelerators.
- **Operating System** (and its kernel) that exposes these HW features.
- **User services** such as libraries, drivers or Board Support Packages (BSPs), that contains ECU-specific drivers so that an RTOS can run on it.
- **Protocols and communications** such as DDS, ROS, etc. The applications will also rely on POSIX to communicate with libraries and other features below them.
- **Applications** will run on top of all the components described before.



## [4.2. Real-Time Operating Systems (RTOSs)](https://youtu.be/IyycN6ldsIs?t=1115)
### [4.2.1. RTOS vs Standard OS](https://youtu.be/IyycN6ldsIs?t=1115)
Chip/HW manufacturers need to make the features of their products available, which can only be done using Operating Systems (OSs), so they must care about SW even HW is their main business. An OS abstract the HW capabilities for the user, so that the CPU, memory, peripherals, etc. can be used in an easier way. This can go from very simple 8-bit microprocessors in a microcontroller to a multi-core 64-bit OS that may need to include security policies or other complex features. The basic features of an OS are:

- Memory management
- I/O management
- Resources allocation
- Error detection and handling
- A kernel for scheduling, communication, synchronization and manage interrupts.

In particular **Real-Timer Operating Systems** (RTOS) offer things that *normal* OSs (GNU/Linux distributions, Mac OS or Windows) that may be installed in desktops, laptops or servesrs do not. Some of these features are that they:

- Are deterministic. i.e. a known behaviour will always be obtained after providing a certain input. The same input will always produce the same behaviour and output.
- Offer hard real-time (RT). They guarantee that a task will be completted in a certain time, even when running them in parallel, without caring about how many other tasks are being executed at this time.
- Are highly responsive to external events, like interrupts, while *normal* OSs focus on user's applications.

The main problem when achieving these features is that, usually, there will be more than one task running, and each of them must be deterministic and be finished in a time lower or equal than the Worst-Case Execution Time (WCET). This is ensured by a **RTOS-oriented task managment**. This is done assigning to each task an state and a priority. The states are `READY`, `RUNNING` and `BLOCKED`. Once the RTOS receives a request of a task that wants to be executed, it will be putted in `READY` state, which will change to `RUNNING` whenever the RTOS decides to start its execution. If the task execution is interrupted by another task with higher priority requesting the resources that are being used, the first task will be moved into `BLOCKED` state until a new execution slot is available.


### [4.2.2. Task Scheduling](https://youtu.be/IyycN6ldsIs?t=1670)
This is possible thanks to the priorities assigned to each task, which are assigned using the **scheduler** provided by the RTOS. There are several scheduling algorithms, being the folowing the main ones:

- **Co-operative**: Each task is executed until it is completed, resulting in a sequential behaviour. Once they finish, they return to its `READY` state because they have been completed, so they will never be in `BLOCKED` state.
- **Round-Robin**: A *quantum* of time will be specified (e.g. 50 ms). Every task will be *preempted* (i.e. stopped and, therefore, moved to `BLOCKED` state) after this quantum time has elapsed. It is very likely that most of the tasks will be interrupted when they have not been completed yet. The system will never be doing nothing (`idle` task), it will always be reserved for the task started in whichever quantum of time it is at.
- **Pre-emptive**: The most common. It is priority-based. Assuming a `task 1` with the highest priority, a `task 2` with a middle one and a `task 3` with the lowest one, if the execution of the 3rd task starts, whenever `task 1` or `2` request to be executed, `task 3` will be preempted and switched to `STOPPED` state until the higher priority task is done. Again, if this new task is interrupted by another one with even higher priority, the same will happen and they will be completed acordingly to their priority. If no task is to be executed, the system will do nothing until one request to be executed.

The main advantage of pre-emptive scheduling is that it allows certain periodicity, which is achieved by assigning the highest priority to the task that must be executed preriodically, which could be some sort of safety monitoring, ensuring clock clicks, etc.


### [4.2.3. Interrupts](https://youtu.be/IyycN6ldsIs?t=2275)
Interrupts will break the cycles previously explained. They can be external (when generated by peripherals) or internal (when generated in a program). When an interrupt occurs, the following process is followed:

1. The task that is being executed is stopped.
2. The context is saved (memory allocation, content of the registers, Program Counter (PC), etc.)
3. Set the Program Counter (PC) to the address of the beginning of the interrupt routine (which should be as fast as possible).
4. Handle the interrupt.
5. Restore the context.
6. Keep going with the execution of the interrupted task.

Regarding the determinism of the system and, in particular, the timing, there are a few time intervals to keep in mind that should be known and that vary from system to system. Those are:

- **Interrupt Latency**: Time between the interrupt generation and the start of its handling (when the current task is stopped and the context is started to been saved).
- **Interrupt Response**: Time between the interrupt generation and the start of its interrupt routine.
- **Interrupt Recovery**: Time in which the context is restored after the end of the interrupt routine.
- **Interrupt Execution Time**: Time between the interrupt generation and the end of the interrupt routine.


### [4.2.4 Memory Management](https://youtu.be/IyycN6ldsIs?t=2455)
This is another critical factor for any RTOS. In standard OSs, whenever accessing to RAM or disks is requested, a `page fault` error can occur (to avoid running out of memory), which is not tolerable for RTOSs because during a `page fault` error the computation is holded while loading missing pages, which is an unpredictable (non-deterministic) operation. This can also happen when using dynamic memory allocation. However, this last case can also introduce memory fragmentation, which introduces uncertainty on how much time will it take to allocate the requested memory.

Therefore, when managing memory, `pagefaults` must be avoided and the memory allocation must be performed carefully. An RTOS will provide mechanisms to do so, allowing pre-allocating memory and static allocation and providing a dedicated API for these delicated tasks and monitoring and debugging capabilities.

It is possible to work with an almost Real-Time memory allocation in Linux systems, as explained in this [introduction to RT systems](https://design.ros2.org/articles/realtime_background). The first thing to do is to avoid `pagefaults` by **locking and pre-loading the memory** that is going to be used as shown here:

```cpp
if (mlockall(MCL_CURRENT|MCL_FUTURE) == -1) {
  perror("mlockall failed");
  exit(-2);
}
unsigned char dummy[MAX_SAFE_STACK];

memset(dummy, 0, MAX_SAFE_STACK);
```

When inlcuded at the beginning of a thread, it will lock and pre-load a certain ammount of memory, so that no `pagefaults` will be produced when trying to access memory inside this thread. `mlockall` locks the process's virtual address space (stack of the thread) into the RAM, while `memset` pre-loads every block of memory of the stack into the cache, avoiding the `pagefaults`.

And, even dynamic memory allocation does not usually grants RT performance, it can be done in an almos safe way by **allocating a dynamic memory pool**:

```cpp
if (mlockall(MCL_CURRENT | MCL_FUTURE))
  perror("mlockall failed:");

/* Turn off malloc trimming.*/
mallopt(M_TRIM_THRESHOLD, -1);

/* Turn off mmap usage. */
mallopt(M_MMAP_MAX, 0);

page_size = sysconf(_SC_PAGESIZE);
buffer = malloc(SOMESIZE);

for (i=0; i < SOMESIZE; i+=page_size) {
  buffer[i] = 0;
}
free(buffer);
```

These additions will allow to use `malloc`/`new`, `free`/`delete` and even STL containers. However, the implementation will depend on the platform, the memory sizes must be predicted accurately, the usage of STL containers will still be dangerous (they have unbounded sized) and it will only work properly for small memory requirements.


### [4.2.5. Micro vs Monolithic Kernels](https://youtu.be/IyycN6ldsIs?t=2650)
There are two main kernel types: **microkernels** and **monolithic kernels**. The main differnce is that **microkernels** separate the memory space dedicated for the user and the one dedicated for the kernel itself, while when using **monolithic kernels**, user and kernel services share the same address space, as explained [here](https://techdifferences.com/difference-between-microkernel-and-monolithic-kernel.html). Microkernels require less memory, are asilly expandable and if a service crashes, it does not affect the kernel (and, therefore, the OS). Monolithic kernels are faster since they can use kernel functions directly (no need of message-based communication). They also provide better CPU scheduling and memory management. However, they require more memory and are more vulnerable to system fails with service crhases.


### [4.2.6. Spatial and Temporal Isolation](https://youtu.be/IyycN6ldsIs?t=2855)
As seen before, it is possible to have several CPUs inside one ECU, which will mean several OSs will compose the system (one per each CPU) and devices being shared between them. To be able to perform this safety, the specialization mechanism for partitioning the resource accessing is necessary. This is based in two concepts:

- **Spatial Isolation**: Mechanisms to manage memory partitioning.
- **Temporal Isolation**: Mechanisms to allow a task to use a resource (such as a CPU) for a certain time.

A few mechanisms that manage these things are:

- **Hypervisor Type 2**: On top of the OS, the hypervisor runs and is able to manage several additional OSs. Examples of this would be VMWare or Virtual Box. They take care of sharing the hardware on the host machine. This is mainly used in servers and desktops. Even it is very flexible, the abstraction is very high level and its determinism is very limited.
- **Hypervisor Type 1** or *bare metal hypervisor*: They are sort of an OS that takes care of spatial and temporal isolation to share the HW among various OSs. Very low level and usually dedicated to a certain CPU type. Mostly used in embedded systems. They are complex to both configure, maintain and certify. Examples are Mentor Graphic Hypervisor, sMCOS hypervisor and QNX hypervisor.
- **Hardware Spatial Isolation**: The hardware itself allows to manage the resources (with the Memory Management Unit (MMU) and the Memory Protection Unit (MPU)). These are easy to configure, maintain and certify. An example for this are Kalray's Manycore MPPA processors, which allows up to 80 CPUs, hardware acceleration for CNNs or complex calculation, hard RT with the eMCOS RTOS, rich OSs or other RTOSs, etc., everything certified with ISO26262 and ASIL B.
- **Tools for Temporal Isolation**: A tool to program/configure, monitor and debug temporal isolation is an OS provided by [Krono-Safe](https://www.krono-safe.com/) named *ASTERIOS*.


### [4.2.7. Automotive RTOS](https://youtu.be/IyycN6ldsIs?t=3155)
Some popular RTOS used in the automotive industry (particularly in the ADAS and AD domains) are:

- **QNX**, by QNX-Blackberry.
- **VxWorks**, by Wind River.
- **Integrity**, by GreenHills.
- **Nucleus**, by Mentor Graphic.
- **eMCOS**, by eSOL.
- **Asterios**, by Krono-Safe.
- **PikeOS**, by SysGo.

As an applications developer for protocol layers on top of an RTOS, such as DDS or ROS, these are the steps to follow:

1. Defining the use cases.
2. Defining the system topology.
3. Defining the determinism strategy.
4. Selecting the hardware.
5. Selecting the RTOS with dependencies on latency, libraries, etc.
6. Set the task priorities.
7. Select and setup the scheduler.
8. Being aware of the interrupt handler.



## [4.3. Data Distribution Service (DDS)](https://youtu.be/IyycN6ldsIs?t=3335)
In this section, the foundations of DDS will be introduced, as well as some advanced concepts. Some of the most useful DDS features appliable to robots applications (and, in general, distributed RT systems) will be covered aswell.


### [4.3.1. The DDS Standard](https://youtu.be/IyycN6ldsIs?t=3375)
DDS is a standard technology for ubiquitous, interoperable, secure, platform independent and RT **data sharing** across network connected devices. It was introduced in 2004 and improved until the 2010's DDSI-RTPS 2.1 version, which has been the main version present for the last 10 years. After it, some improvements regarding the types and its integration with newer C++ standards were made until the present 2020.

The Data Distribution Service (DDS) standard can be divided by layers. It sits on top of an IP transport (after the (1) physical and (2) data link layers). After the (3) network layer, comes the (4) transport one, which is based in UDP and TCP (TCP is not in the standard yet). The ISO OSI's 5th layer, the *session* one, is the big part of the standard and what guarantees interoperability (DDSI-RTPS). On top of it, the DDS layer is located, providing abstraction for the DDS primitives and the API (including other specifications such as RPC, security and X-types). Applications in different languages will use the DDS API to use DDS.

**Remote Procedure Calls** (DDS-RPC) extend the DDS's abstraction to support distributed service definition, giving DDS users the hability to run traditional client-server architectures on top of DDS. It is only an added features and its usage will depend on the application, but one of DDS's advantages is to promote data centricity and decoupled distributed systems. By using RPC, the problems of client-server designs will be introduced in the applications, adding concerns about availability and fault tolerance, among others.

**DDS Security** defines a data-centric security architecture, allowing authentication, access control, cryptography and logging, among other things, in a *plug-in-based* way.

Regarding **eXtensible Types** (DDS X-Types), it was a major innovation for DDS because, before, DDS typing was nominal, becoming structural after the addition of this specification. The difference is that *nominal* type systems will compare (and operate assigning, adding, etc.) instances based on their name, hwile *structural* ones will do so based on their structures. This is, if two classes have the same components, systems with nominal typing will not allow them to interact because they have different names, while structural ones will allow it unless there is some strucutral difference. *Nominal* typing will be more convinient when two classes may be identical but serve different purposes. Object-Oriented Languages (OOLs) are usually nominally typed (C++, Java, Swift, etc.), while functional languages tend to the structural typing (OCaml, Haskell, Elm, etc.).

#### [4.3.1.1. DDS Applications](https://youtu.be/IyycN6ldsIs?t=3780)
DDS usage is widely spreaded. For years, DDS has been used for sharing data across different component of **autonomous vehicles**, particularly in agriculture. **Smart cities**-related projects also use DDS for data sources and sinks and even to control equipment. **Smart grids** for the energy industry use DDS to integrate and normalise data sharing amond different elements of a smart grid (e.g. to align the phase of the current periodically at high frequency). **Smart green houses** use DDS to monitor and control the I/O of their systems. DDS is the core of many **combat systems**, specially in the naval sector, distributing soft and hard RT sensor and actuator data. The **NASA's launch systems** use DDS to stream messages at almost two thirds that Twitter needs. DDS is also used for sharing flight data in **air traffic control** centers. The **NASA's SMART NAS**, a project to improve air traffic management, also uses DDS. **Unmanned Air Vehicles** (UAVs) use DDS to distribute information of several thousands of sensor targets (first in the control station but now also in the aircrafts). **Airbus's simulators** manage all the data in DDS (converting it to the ARINC429 bus with the applications). **Smart factories** integrate data horizontally and vertically across SCADA layers using DDS. The **ELT telescope** control 100000 mirrors at 100 Hz with DDS. **Medical devices** share data between aquisition, processing and visualization with DDS. DDS is very used in **robotics**, being the heart of ROS 2 and the base for other proprietary systems of individual vendors.

#### [4.3.1.2. DDS Advantages](https://youtu.be/IyycN6ldsIs?t=3935)
DDS is used in these applications because its advantages:

- High level and powerful abstractions.
- Easiness to build highly modular and distributed systems.
- Easiness to solve hard distributed system problems, such as:
  - Fault-tolerance
  - Scalability
  - Asymmetry. i.e. having components with very different computing capabilities working together in the system (regarding network latency or bandwidth).

In general, DDS allows to seal together very heterogeneous environments while keeping a single, elegant and efficient abstraction.

DDS is also **platform independent**, being able to run in enterprise, desktop, embedded, RT, mobile and web platforms. Moreover, DDS applications can be written in several programming languages (**polyglocy**), most vendors providing APIs for C/C++, Python, Java, Scala, .net, JavaScript, etc.


### [4.3.2. DDS Foundations](https://youtu.be/IyycN6ldsIs?t=4050)




### 4.3.3. Advanced DDS Concepts



### 4.3.4. DDS for Robotics



