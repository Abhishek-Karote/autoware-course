# Lecture 04: Platform (ECUs, RTOS, and DDS)
[![Autoware.Auto badge](https://img.shields.io/badge/Autoware-Auto-orange.svg)](https://www.autoware.auto)

This lecture is provided by [Stephane Strahm](https://www.linkedin.com/in/stephanestrahm/) (Product Manager at Kalray) and by [Angelo Corsaro](https://www.linkedin.com/in/corsaro/) (AD-Link CTO). The lecture is available in YouTube:

[![Lecture video](https://img.youtube.com/vi/IyycN6ldsIs/0.jpg)](https://www.youtube.com/watch?v=IyycN6ldsIs&list=PLL57Sz4fhxLpCXgN0lvCF7aHAlRA5FoFr&index=4)

The target will be to cover the underlying technologies under the systems that run Autoware.Auto and ROS 2. The **first part** will include three topics: (1) Electronic Control Units (ECUs), (2) Real Time Operating Systems (RTOS), and (3) design and optimization criterias. Next, the **second part** will cover ROS 2's middleware, Data Distribution Service (DDS).

The provided PDFs can be found in the Apex.AI's [autowareclass2020 repository](https://gitlab.com/ApexAI/autowareclass2020/-/blob/master/lectures/04_Platform), in GitLab. There is one for the [first](https://gitlab.com/ApexAI/autowareclass2020/-/blob/master/lectures/04_Platform/ECUandRTOS.pdf) and another for the [second](https://gitlab.com/ApexAI/autowareclass2020/-/blob/master/lectures/04_Platform/DDSExplained.pdf) part of the lecture. The first part includes ECUs and RTOSs and the second, DDS. The PDFs are included in the *resources* folder of this directory. 



## [4.1. Electronic Control Units (ECUs)](https://youtu.be/IyycN6ldsIs?t=75)
In a [SAE Level 2](https://www.sae.org/news/2019/01/sae-updates-j3016-automated-driving-graphic) vehicle, more than 80 ECUs can be found, destinated to control systems such as the audio, video, navigation, motor control, Advanced Driving Assitance System (ADAS), Autonomous Driving (AD), etc. This number has been increased as new features and technologies were introduced in vehicles, which increased both the complexity of the system and the concerns about the safety. In this lecture, we will focus on ADAS and AD ECUs. The ADAS one will assist the driver monitoring its speed, using sensors during parking, alert of the presence of radars or other vehicles nearby, etc. All these things while the driver remain in control of the vehicle. The AD ECU will make the vehicle able to be driven by itself.

The **ADAS and AD ECU functions** can be classified in four different groups:

- **Sensors** such as cameras, GPS, RADAR or LIDAR. This module is in charge of gathering data about the vehicle's environment. This data will be forwarded to the perception module. By combining data from these sensors, a more reliable and robust system is achieved.
- **Perception**: Its task is to process the data obtained with the sensors to generate higher-level information. Some ways of doing so is using localization, tracking, detection, classification and/or segmentation techniques.
- **Planning**: With the knowledge generated by the perception module, the planning one will decide which behaviour to perform and compute a trajectory that implements it. It is also in charge of planning long/global routes and usually tries to predict the behaviour of the other elements around the vehicle to plan safe actions.
- **Control**: Once knowing where and how the vehicle must move, the control module will manage the engine, steering wheel, brakes and other systems to reach the targets in optimal ways.


### [4.1.1. Automotive ECUs](https://youtu.be/IyycN6ldsIs?t=655)
Automotive ECUs will require different **components**. The main will be:

- **Inputs and outputs** to connect the sensors and actuators so that they can be used by the ECU.
- **Application processors**: To fuse the data from the sensors and perform the planning and control. Specific processors may be needed to work with specific types of data, such as Digital Singal Processors (DSPs) for signals, others for visual information, etc. They are powerful components, both x86 and ARM are used.
- **Accellerator units**: Some heavy computation may be needed for, for examples, running CNNs or heavy mathematical algorithms. Today, those heavy calculations are usually done solved with GPUs.
- **Safety processors**: Given how critical the automotive applications are, it is essential to have fully reliable systems. This is why there are processors used exclusively for safety-related tasks, which are monitoring the overall system. Appart of this, the [ISO 26262](https://www.iso.org/obp/ui/#iso:std:iso:26262:-2:ed-2:v1:en) defines development and verification processes that must be followed to ensure the required safety level specified by the [Automotive Safety Integrity Level (ASIL)](https://www.synopsys.com/automotive/what-is-asil.html) levels.

The big ammount of required functions and the extense history and evolution has left us with a large spectrum of boards and chips. A few of them are the [Kalray products](https://www.kalrayinc.com/products/), the NXP's [BlueBox](https://www.nxp.com/design/development-boards/automotive-development-platforms/nxp-bluebox-autonomous-driving-development-platform:BLBX) and [S32G](https://www.nxp.com/products/processors-and-microcontrollers/arm-processors/s32-automotive-platform/s32g-processors-for-vehicle-networking:S32G274A)], the [Tesla's AD board](https://www.theverge.com/2019/4/22/18511594/tesla-new-self-driving-chip-is-here-and-this-is-your-best-look-yet), the [Infineron](https://www.infineon.com/cms/en/) safety processors or the [NVIDIA options](https://www.nvidia.com/en-us/self-driving-cars). There are many options for production, pre-production and development that are constantly evolving thanks to the revolutions introduced by tier 1 or Original Equipment Manufacturers (OEMs).


### [4.1.2. Supporting Software for ECUs](https://youtu.be/IyycN6ldsIs?t=975)
To have all these functions runing, abstraction levels are adopted in the software of the ECUs. These levels will be:

- **Hardware**: Composed by application and safety processors and accelerators.
- **Operating System** (and its kernel) that exposes these HW features.
- **User services** such as libraries, drivers or Board Support Packages (BSPs), that contains ECU-specific drivers so that an RTOS can run on it.
- **Protocols and communications** such as DDS, ROS, etc. The applications will also rely on POSIX to communicate with libraries and other features below them.
- **Applications** will run on top of all the components described before.



## [4.2. Real-Time Operating Systems (RTOSs)](https://youtu.be/IyycN6ldsIs?t=1115)
### [4.2.1. RTOS vs Standard OS](https://youtu.be/IyycN6ldsIs?t=1115)
Chip/HW manufacturers need to make the features of their products available, which can only be done using Operating Systems (OSs), so they must care about SW even HW is their main business. An OS abstract the HW capabilities for the user, so that the CPU, memory, peripherals, etc. can be used in an easier way. This can go from very simple 8-bit microprocessors in a microcontroller to a multi-core 64-bit OS that may need to include security policies or other complex features. The basic features of an OS are:

- Memory management
- I/O management
- Resources allocation
- Error detection and handling
- A kernel for scheduling, communication, synchronization and manage interrupts.

In particular **Real-Timer Operating Systems** (RTOS) offer things that *normal* OSs (GNU/Linux distributions, Mac OS or Windows) that may be installed in desktops, laptops or servesrs do not. Some of these features are that they:

- Are deterministic. i.e. a known behaviour will always be obtained after providing a certain input. The same input will always produce the same behaviour and output.
- Offer hard real-time (RT). They guarantee that a task will be completted in a certain time, even when running them in parallel, without caring about how many other tasks are being executed at this time.
- Are highly responsive to external events, like interrupts, while *normal* OSs focus on user's applications.

The main problem when achieving these features is that, usually, there will be more than one task running, and each of them must be deterministic and be finished in a time lower or equal than the Worst-Case Execution Time (WCET). This is ensured by a **RTOS-oriented task managment**. This is done assigning to each task an state and a priority. The states are `READY`, `RUNNING` and `BLOCKED`. Once the RTOS receives a request of a task that wants to be executed, it will be putted in `READY` state, which will change to `RUNNING` whenever the RTOS decides to start its execution. If the task execution is interrupted by another task with higher priority requesting the resources that are being used, the first task will be moved into `BLOCKED` state until a new execution slot is available.


### [4.2.2. Task Scheduling](https://youtu.be/IyycN6ldsIs?t=1670)
This is possible thanks to the priorities assigned to each task, which are assigned using the **scheduler** provided by the RTOS. There are several scheduling algorithms, being the folowing the main ones:

- **Co-operative**: Each task is executed until it is completed, resulting in a sequential behaviour. Once they finish, they return to its `READY` state because they have been completed, so they will never be in `BLOCKED` state.
- **Round-Robin**: A *quantum* of time will be specified (e.g. 50 ms). Every task will be *preempted* (i.e. stopped and, therefore, moved to `BLOCKED` state) after this quantum time has elapsed. It is very likely that most of the tasks will be interrupted when they have not been completed yet. The system will never be doing nothing (`idle` task), it will always be reserved for the task started in whichever quantum of time it is at.
- **Pre-emptive**: The most common. It is priority-based. Assuming a `task 1` with the highest priority, a `task 2` with a middle one and a `task 3` with the lowest one, if the execution of the 3rd task starts, whenever `task 1` or `2` request to be executed, `task 3` will be preempted and switched to `STOPPED` state until the higher priority task is done. Again, if this new task is interrupted by another one with even higher priority, the same will happen and they will be completed acordingly to their priority. If no task is to be executed, the system will do nothing until one request to be executed.

The main advantage of pre-emptive scheduling is that it allows certain periodicity, which is achieved by assigning the highest priority to the task that must be executed preriodically, which could be some sort of safety monitoring, ensuring clock clicks, etc.


### [4.2.3. Interrupts](https://youtu.be/IyycN6ldsIs?t=2275)
Interrupts will break the cycles previously explained. They can be external (when generated by peripherals) or internal (when generated in a program). When an interrupt occurs, the following process is followed:

1. The task that is being executed is stopped.
2. The context is saved (memory allocation, content of the registers, Program Counter (PC), etc.)
3. Set the Program Counter (PC) to the address of the beginning of the interrupt routine (which should be as fast as possible).
4. Handle the interrupt.
5. Restore the context.
6. Keep going with the execution of the interrupted task.

Regarding the determinism of the system and, in particular, the timing, there are a few time intervals to keep in mind that should be known and that vary from system to system. Those are:

- **Interrupt Latency**: Time between the interrupt generation and the start of its handling (when the current task is stopped and the context is started to been saved).
- **Interrupt Response**: Time between the interrupt generation and the start of its interrupt routine.
- **Interrupt Recovery**: Time in which the context is restored after the end of the interrupt routine.
- **Interrupt Execution Time**: Time between the interrupt generation and the end of the interrupt routine.


### [4.2.4 Memory Management](https://youtu.be/IyycN6ldsIs?t=2455)
This is another critical factor for any RTOS. In standard OSs, whenever accessing to RAM or disks is requested, a `page fault` error can occur (to avoid running out of memory), which is not tolerable for RTOSs because during a `page fault` error the computation is holded while loading missing pages, which is an unpredictable (non-deterministic) operation. This can also happen when using dynamic memory allocation. However, this last case can also introduce memory fragmentation, which introduces uncertainty on how much time will it take to allocate the requested memory.

Therefore, when managing memory, `pagefaults` must be avoided and the memory allocation must be performed carefully. An RTOS will provide mechanisms to do so, allowing pre-allocating memory and static allocation and providing a dedicated API for these delicated tasks and monitoring and debugging capabilities.

It is possible to work with an almost Real-Time memory allocation in Linux systems, as explained in this [introduction to RT systems](https://design.ros2.org/articles/realtime_background). The first thing to do is to avoid `pagefaults` by **locking and pre-loading the memory** that is going to be used as shown here:

```cpp
if (mlockall(MCL_CURRENT|MCL_FUTURE) == -1) {
  perror("mlockall failed");
  exit(-2);
}
unsigned char dummy[MAX_SAFE_STACK];

memset(dummy, 0, MAX_SAFE_STACK);
```

When inlcuded at the beginning of a thread, it will lock and pre-load a certain ammount of memory, so that no `pagefaults` will be produced when trying to access memory inside this thread. `mlockall` locks the process's virtual address space (stack of the thread) into the RAM, while `memset` pre-loads every block of memory of the stack into the cache, avoiding the `pagefaults`.

And, even dynamic memory allocation does not usually grants RT performance, it can be done in an almos safe way by **allocating a dynamic memory pool**:

```cpp
if (mlockall(MCL_CURRENT | MCL_FUTURE))
  perror("mlockall failed:");

/* Turn off malloc trimming.*/
mallopt(M_TRIM_THRESHOLD, -1);

/* Turn off mmap usage. */
mallopt(M_MMAP_MAX, 0);

page_size = sysconf(_SC_PAGESIZE);
buffer = malloc(SOMESIZE);

for (i=0; i < SOMESIZE; i+=page_size) {
  buffer[i] = 0;
}
free(buffer);
```

These additions will allow to use `malloc`/`new`, `free`/`delete` and even STL containers. However, the implementation will depend on the platform, the memory sizes must be predicted accurately, the usage of STL containers will still be dangerous (they have unbounded sized) and it will only work properly for small memory requirements.


### [4.2.5. Micro vs Monolithic Kernels](https://youtu.be/IyycN6ldsIs?t=2650)
There are two main kernel types: **microkernels** and **monolithic kernels**. The main differnce is that **microkernels** separate the memory space dedicated for the user and the one dedicated for the kernel itself, while when using **monolithic kernels**, user and kernel services share the same address space, as explained [here](https://techdifferences.com/difference-between-microkernel-and-monolithic-kernel.html). Microkernels require less memory, are asilly expandable and if a service crashes, it does not affect the kernel (and, therefore, the OS). Monolithic kernels are faster since they can use kernel functions directly (no need of message-based communication). They also provide better CPU scheduling and memory management. However, they require more memory and are more vulnerable to system fails with service crhases.


### [4.2.6. Spatial and Temporal Isolation](https://youtu.be/IyycN6ldsIs?t=2855)
As seen before, it is possible to have several CPUs inside one ECU, which will mean several OSs will compose the system (one per each CPU) and devices being shared between them. To be able to perform this safety, the specialization mechanism for partitioning the resource accessing is necessary. This is based in two concepts:

- **Spatial Isolation**: Mechanisms to manage memory partitioning.
- **Temporal Isolation**: Mechanisms to allow a task to use a resource (such as a CPU) for a certain time.

A few mechanisms that manage these things are:

- **Hypervisor Type 2**: On top of the OS, the hypervisor runs and is able to manage several additional OSs. Examples of this would be VMWare or Virtual Box. They take care of sharing the hardware on the host machine. This is mainly used in servers and desktops. Even it is very flexible, the abstraction is very high level and its determinism is very limited.
- **Hypervisor Type 1** or *bare metal hypervisor*: They are sort of an OS that takes care of spatial and temporal isolation to share the HW among various OSs. Very low level and usually dedicated to a certain CPU type. Mostly used in embedded systems. They are complex to both configure, maintain and certify. Examples are Mentor Graphic Hypervisor, sMCOS hypervisor and QNX hypervisor.
- **Hardware Spatial Isolation**: The hardware itself allows to manage the resources (with the Memory Management Unit (MMU) and the Memory Protection Unit (MPU)). These are easy to configure, maintain and certify. An example for this are Kalray's Manycore MPPA processors, which allows up to 80 CPUs, hardware acceleration for CNNs or complex calculation, hard RT with the eMCOS RTOS, rich OSs or other RTOSs, etc., everything certified with ISO26262 and ASIL B.
- **Tools for Temporal Isolation**: A tool to program/configure, monitor and debug temporal isolation is an OS provided by [Krono-Safe](https://www.krono-safe.com/) named *ASTERIOS*.


### [4.2.7. Automotive RTOS](https://youtu.be/IyycN6ldsIs?t=3155)
Some popular RTOS used in the automotive industry (particularly in the ADAS and AD domains) are:

- **QNX**, by QNX-Blackberry.
- **VxWorks**, by Wind River.
- **Integrity**, by GreenHills.
- **Nucleus**, by Mentor Graphic.
- **eMCOS**, by eSOL.
- **Asterios**, by Krono-Safe.
- **PikeOS**, by SysGo.

As an applications developer for protocol layers on top of an RTOS, such as DDS or ROS, these are the steps to follow:

1. Defining the use cases.
2. Defining the system topology.
3. Defining the determinism strategy.
4. Selecting the hardware.
5. Selecting the RTOS with dependencies on latency, libraries, etc.
6. Set the task priorities.
7. Select and setup the scheduler.
8. Being aware of the interrupt handler.



## [4.3. Data Distribution Service (DDS)](https://youtu.be/IyycN6ldsIs?t=3335)
In this section, the foundations of DDS will be introduced, as well as some advanced concepts. Some of the most useful DDS features appliable to robots applications (and, in general, distributed RT systems) will be covered aswell.


### [4.3.1. The DDS Standard](https://youtu.be/IyycN6ldsIs?t=3375)
DDS is a standard technology for ubiquitous, interoperable, secure, platform independent and RT **data sharing** across network connected devices. It was introduced in 2004 and improved until the 2010's DDSI-RTPS 2.1 version, which has been the main version present for the last 10 years. After it, some improvements regarding the types and its integration with newer C++ standards were made until the present 2020.

The Data Distribution Service (DDS) standard can be divided by layers. It sits on top of an IP transport (after the (1) physical and (2) data link layers). After the (3) network layer, comes the (4) transport one, which is based in UDP and TCP (TCP is not in the standard yet). The ISO OSI's 5th layer, the *session* one, is the big part of the standard and what guarantees interoperability (DDSI-RTPS). On top of it, the DDS layer is located, providing abstraction for the DDS primitives and the API (including other specifications such as RPC, security and X-types). Applications in different languages will use the DDS API to use DDS.

**Remote Procedure Calls** (DDS-RPC) extend the DDS's abstraction to support distributed service definition, giving DDS users the hability to run traditional client-server architectures on top of DDS. It is only an added features and its usage will depend on the application, but one of DDS's advantages is to promote data centricity and decoupled distributed systems. By using RPC, the problems of client-server designs will be introduced in the applications, adding concerns about availability and fault tolerance, among others.

**DDS Security** defines a data-centric security architecture, allowing authentication, access control, cryptography and logging, among other things, in a *plug-in-based* way.

Regarding **eXtensible Types** (DDS X-Types), it was a major innovation for DDS because, before, DDS typing was nominal, becoming structural after the addition of this specification. The difference is that *nominal* type systems will compare (and operate assigning, adding, etc.) instances based on their name, hwile *structural* ones will do so based on their structures. This is, if two classes have the same components, systems with nominal typing will not allow them to interact because they have different names, while structural ones will allow it unless there is some strucutral difference. *Nominal* typing will be more convinient when two classes may be identical but serve different purposes. Object-Oriented Languages (OOLs) are usually nominally typed (C++, Java, Swift, etc.), while functional languages tend to the structural typing (OCaml, Haskell, Elm, etc.).

#### [4.3.1.1. DDS Applications](https://youtu.be/IyycN6ldsIs?t=3780)
DDS usage is widely spreaded. For years, DDS has been used for sharing data across different component of **autonomous vehicles**, particularly in agriculture. **Smart cities**-related projects also use DDS for data sources and sinks and even to control equipment. **Smart grids** for the energy industry use DDS to integrate and normalise data sharing amond different elements of a smart grid (e.g. to align the phase of the current periodically at high frequency). **Smart green houses** use DDS to monitor and control the I/O of their systems. DDS is the core of many **combat systems**, specially in the naval sector, distributing soft and hard RT sensor and actuator data. The **NASA's launch systems** use DDS to stream messages at almost two thirds that Twitter needs. DDS is also used for sharing flight data in **air traffic control** centers. The **NASA's SMART NAS**, a project to improve air traffic management, also uses DDS. **Unmanned Air Vehicles** (UAVs) use DDS to distribute information of several thousands of sensor targets (first in the control station but now also in the aircrafts). **Airbus's simulators** manage all the data in DDS (converting it to the ARINC429 bus with the applications). **Smart factories** integrate data horizontally and vertically across SCADA layers using DDS. The **ELT telescope** control 100000 mirrors at 100 Hz with DDS. **Medical devices** share data between aquisition, processing and visualization with DDS. DDS is very used in **robotics**, being the heart of ROS 2 and the base for other proprietary systems of individual vendors.

#### [4.3.1.2. DDS Advantages](https://youtu.be/IyycN6ldsIs?t=3935)
DDS is used in these applications because its advantages:

- High level and powerful abstractions.
- Easiness to build highly modular and distributed systems.
- Easiness to solve hard distributed system problems, such as:
  - Fault-tolerance
  - Scalability
  - Asymmetry. i.e. having components with very different computing capabilities working together in the system (regarding network latency or bandwidth).

In general, DDS allows to seal together very heterogeneous environments while keeping a single, elegant and efficient abstraction.

DDS is also **platform independent**, being able to run in enterprise, desktop, embedded, RT, mobile and web platforms. Moreover, DDS applications can be written in several programming languages (**polyglocy**), most vendors providing APIs for C/C++, Python, Java, Scala, .net, JavaScript, etc.


### [4.3.2. DDS Foundations](https://youtu.be/IyycN6ldsIs?t=4050)
The idea is to create a *data space* in which application can write and read data enjoying both spatial and temporal decoupling. *Spatial decoupling* meaning that the data consumer can get data and work with it even if the producer has already deleted it from its system. *Temporal decoupling* means that the writers will not be influenced by how many readers are (or if any exists).

The data is modeled in *topics*, which is some sort of *class*, being defined by the topic's name, the type of information published in it and a Quality of Service (QoS) that captures the non-functional properties of the information. QoS allos to express temporal and availability constraints for the data.

Given that the *data space* that DDS creates is decentralized, there are **no bottlenecks or single points of failure**. Another feature of DDS is **dynamic discovery**, which get to discover each other (the publisher finds the subscriber and viceversa), isolating applications from network topology and connectivity details. The **adaptive connectivity** offered by DDS is related to this. It will automatically choose the most effective way of sharing data between nodes. For example, when one application is producing data and only one is reading it, *unicast* will be probably chosen as the way to transmit it. If another reader appears and both can read from the same multicast IP address, communication will switch from *unicast* to *multicast* to optimize the network usage.

#### [4.3.2.1. Lab 01. First Application](https://youtu.be/IyycN6ldsIs?t=4315)
For the labs, [Eclipse Cyclone DDS](https://github.com/eclipse-cyclonedds/cyclonedds) will be used, that is an open-source DDS implementation that was started aiming to be the best one and the Go-To option. Two C++ programs will be written, one for writing and another one for reading data, both of them using DDS.

The writer will look like this (assuming a few declarations before it):

```cpp
#include <dds/dds.hpp>

int main(int, char**)
{
  dds::domain::DomainParticipant dp(0);
  dds::topic::Topic<Meter> topic("SmartMeter");
  dds::pub::Publisher pub(dp);
  dds::pub::DataWriter<Meter> dw(pub, topic);

  while(!done)
  {
    auto value = readMeter();
    dw.write(value);
    std::this_thread::sleep_for(SAMPLING_PERIOD);
  }

  return 0;
}
```

A domain participant, topic, publisher and data writer that uses this publisher to publish on the declared topic are created. The `while` loop will periodically read a meter, write the value with the data writer and wait until the next sample has to be taken.

On the other side, the reader will be:

```cpp
#include <dds/dds.hpp>

int main(int, char**)
{
  dds::domain::DomainParticipant dp(0);
  dds::topic::Topic<Meter> topic("SmartMeter");
  dds::pub::Subscriber sub(dp);
  dds::pub::DataReader<Meter> dr(sub, topic);

  auto samples = dr.read();
  std::for_each(samples.begin(), samples.end(), [](Sample<Meter>& sample)
  {
    std::cout << sample.data() << std::endl;
  });

  return 0;
}
```

It will use the same topic type (`Meter`) and name (`SmartMeter`), but this time a subscriber and a node reader are created. Next, the program will iterate through the received samples, printing the data on them during the process. There are other options such as waiting for data to be available or defining a callback that will be triggered each time new data is available.

In order to run this example, an implementation of DDS must be installed in our local machine. As said before, Cyclone DDS will be the chosen one, which can be downloaded from its [GitHub repository](https://github.com/eclipse-cyclonedds/cyclonedds), which also contains detailed instruction on its installation. The C++ API will also be needed to use DDS from C++ programs. Instructions concerning this are also included in the repository. The full C++ files and CMakeLists files are shown in the video. Once having all together in a directory, they can be built as a normal C++ project:

```bash
$ mkdir build
$ cd build
$ cmake ..
$ make
```

After this, the writer and the reader must be executed in two different terminals.


### [4.3.3. Advanced DDS Concepts](https://youtu.be/IyycN6ldsIs?t=4730)
A sample topic could be named *LightBulb*, being of type *LightBulbState*, which would contain its serial number, luminosity, hue and if it is on or off. It will be published/readed with some QoS. The type would be defined as follows:

```cpp
struct LightBulbState
{
  string sn;
  float luminosity;
  long hue;
  boolean on;
};
#pragma keylist LightBulbState sn
```

The last `pragma` line marks the `sn` component (serial number) as the *key value* of the topic, meaning that for each topic whose `sn` attribute is different, we will have a **topic instance**. This means that publishing in a LightBulb topic with the same `sn` but different `luminosity`, `hue` and `on` values, will create different samples in the same topic, while changing the `sn` would generate a new independent instance of the topic, representing another light bulb. DDS provides ways to manage the **life cycles of the instances**, making it possible to detect when they are no longer relevant for the system and, thus, dispose them.

All the information in DDS lives in a *domain*, organised in *partitions*. The domain can not be crossed and each sample of a topic instance will be read and written using one or more partitions.

#### [4.3.3.1. DDS Entities](https://youtu.be/IyycN6ldsIs?t=4990)
DDS provides **entities** to control where and what data is written/read. The key DDS entities are:

- **Topic**: Where the data is published at/read from.
- **Domain Participant** (DP): It gives access to a domain.
- **Publishers and subscribers** (pub/sub): They use the domain participant they are associated with to choose where to write/read data. i.e. they define which partition is going to be used.
- **Data writer and reader** (DW/DR): These are the entities that *choose* which data the application will work with. It is through them through what the data is published/read into the partition defined by the pub/sub inside the domain chosen with the DP.
- **QoS Policies**: Control *how* data is shared and, therefore, influence how the resources are utilised.

Therefore, the **matching model** would be defined as follows: For data to flow from a DW to a DR, they need to:

- Be in the same domain. i.e. their DPs are providing them with access to the same domain.
- The DR's sub and the DW's pub must be using the same partition.
- Their QoS policies offered by the DW must exceed or, at least, match those requested by the DR. 

Regarding the **storage model**, each DW and DR is associated a *sample cache*. DDS will project content of the DW's cache in the matching DRs' ones. Therefore, all operations are local and, in most cases, non-blocking. Reading will never be blocking and writting will only block if there are not enaough resources available (which, depending on the case, could be fixed with the QoS settings).

#### [4.3.3.2. Content Awareness](https://youtu.be/IyycN6ldsIs?t=5265)
It can be the case of wanting to receive all data or only a subset of this data. This is why DDS provides *content filtering*. It can be used to project in the local cache only the data satisfying a certain condition in order to avoid useless processing. For example, a road flash radar for speed monitoring will only be interested in processing the information if the speed (subset of all the aquired data) is over the speed limit of the road where it is.

Another DDS feature are the **queries**. They can be used to select a subset of data from the data that is already in the local cache. Again, an SQL predicate will be used to get only the subset of data satisfying a certain condition.

#### [4.3.3.3. Stream Durability](https://youtu.be/IyycN6ldsIs?t=5415)
*Stream durability* refers to which data will be available and under which circumstances will it happen. This can be controlled using QoS settings, that make it possible to retain and make available *old* data for *late joiners* (i.e. replay data). It is possible to store only the last sample, the last *n* samples or even every sample ever written. Durability can be classified in three types:

- **Volatile Durability**: No durability. Each new comer will be able to access only the data published while it is subscribed.
- **Transient Durability** (or local): A certain amount of data will be available for late joiners as far as the data producer/publisher is still running.
- **Durable Durability**: A certain amount of data will be available wether or not the producer is running.

#### [4.3.3.4. Stream Reliability](https://youtu.be/IyycN6ldsIs?t=5560)
In DDS, there are different reliability levels, which are:

- **Best Effor Reliability**: An arbitraty subsequence of the written samples will be delivered. The data drop can be caused by network loss or flow control issues.
- **Last N-Values Reliability**: The default *reliable reliability* in DDS. Under stationary conditions, it guarantees to receive the last published n-samples. Samples outside this n-values history, may (or may not) be dropped for flow or resource control.
- **Reliable Reliability**: It is also possible to have TCP/IP-like reliability in DDS, in which every sample is delivered. However, given that this could cause infinite resource requeriments or blocking time, these aspects can be managed with QoS settings. This is mostly used for events that happen rarely, such as alarms.

#### [4.3.3.5. Fault-Tolerance](https://youtu.be/IyycN6ldsIs?t=5755)
DDS provides **failure detections** features to detect conventional crashes as well as performance ones. They are detected using the *liveliness* and the *deadline* policies, respectively. The subscriber will be notified when a *traditonal fault* is detected or when some data is not received within the expected timeframe.

QoS provides a **fault-masking** mechanism that allows to *replicate* sources transparently switching over to another source when either a traditional fault or performance failure is detected.


### [4.3.4. Further Details](https://youtu.be/IyycN6ldsIs?t=5815)
#### [4.3.4.1. QoS Policies](https://youtu.be/IyycN6ldsIs?t=5815)
DDS provides with more than 20 standard QoS policies, which are often combined to achieve a certain behavior. QoS policies can be classified in:

- **Immutable** policies: Once setted, it can not be changed.
- **RxO** policies (Request vs Offer): Policies that impact end-to-end behaviors, in which the sender must match or exceed the requirements specified by the reader. 
- **Local** policies: They are local policies that do not affect end-to-end behaviors.

**RxO Policies** are the most common. The ones in this category are durability, destination order, reliability, latency budget, deadline, ownership, liveliness and presentation.

#### [4.3.4.2. DDS in Robotics](https://youtu.be/IyycN6ldsIs?t=5895)
DDS matches very well with robotics because the following characteristics:

- Data-centric abstraction.
- Descentralised architecture, avoiding potential fatal failures due to single-point failures.
- Data intensive architecture.
- RT behavior by setting deadlines, detecting performance failure, using replicated sources monitoring liveliness, etc.
- Performance.
- QoS-driven non-functional properties that can be programatically expressed.

**Temporal properties** are particularlly important for robotics communications, specially when it comes to control modules. There are 5 QoS policies that allow to control **thoughput latency and trade-off**. These are:

- The inbound throughput can be limited by using `TimeBasedFilter`, limiting the minimum arrival time of the data.
- The trade-offf (throughput and latency) can be controleld with the `LatencyBudget`. If it is setted to 0, data will be sent on the network inmediately, optimizing latency, but it may harm the throughput. This can be incremented to choose to wait more and send bigger packages instead of more smaller ones.
- `Deadline` and `TransportPriority` allows to choose between producing data (and receiving it quicker) or assigning priority to certain data.

Regarding **data availability**, there are 4 QoS policies to control it:

- **Lifespan**: It decides when does the system's garbage collector collects the data.
- **History**: Specifies how many samples of a topic instance will be kept in the cache.
- **Durability**: Fow how long the history will be kept.
- **Durability Service**: Defines if the history will be available for late joiners even when the producer is gone.

The **reader cache** can be controlled by:

- **History**: Again, to decide how many samples will be stored.
- **Resource Limits**: Memory limits for the cache.
- **Reader Data Lifecycle**: Control the garbage collection of disposed instances.
- **Destination Order**: To decide which data will be inputted in the reader's cache if there are multiple writers writting in the same topic instance.

[This article](https://index.ros.org/doc/ros2/Concepts/DDS-and-ROS-middleware-implementations/) goes into more detail about how to use DDS in ROS 2.

#### [4.3.4.3. QoS Modeling Idioms](https://youtu.be/IyycN6ldsIs?t=6155)
When developing a system that uses DDS, it is key to identify what is the **state** of the system and which are its **events**. An *state* is something that is always present, time-continous, such as the temperature of a room. *Events* are discrete, such as the temperature being higher than 25 ºC or a collision alert.

States can be classified in:

- **Soft States**: Periodically updated states, such as some data produced periodically by a sensor. The QoS combination to model a soft state would be:
  - Reliability      -> BestEffort
  - Durability       -> Volatile
  - History          -> KeepLast(n) *[most of the time, n=1]*
  - Deadline         -> udatePeriod
  - LatencyBudget    -> updatePeriod/3 *[rule of thumb]*
  - DestinationORder -> SourceTimestamp *[if multiple writers will write in the same instance]*
- **Hard States**: They are sporadically updated and they usually require temporal persistance. An example would be some sort of robot configuration that takes a lot to compute, e.g. 2h. The QoS for these states would be:
  - Reliability         -> Reliable
  - Durability          -> Transient | Persistent
  - History             -> KeepLast(n) *[most of the time, n=1]*
  - DestinationOrder    -> SourceTimestamp *[if multiple writers will write in the same instance]*
  - WriterDataLIfecycle -> autodispose_unregistered_instances = false

An **event** will be represented as follows:

- Reliability         -> Reliable
- Durability          -> any *[depends on system requirements]*
- History             -> KeepAll *[on both DataWriter and DataReader]*
- DestinationOrder    -> SourceTimestamp
- WriterDataLifecycle -> autodispose_unregistered_instances = false
- ResourceLimits      -> *[define appropriate bounds]*

#### [4.3.4.4. Performance](https://youtu.be/IyycN6ldsIs?t=6455)
This will be evaluated, once again, in the context of [Cyclone DDS](https://github.com/eclipse-cyclonedds/cyclonedds). It is one of the top performing DDS implementations available, providing a **latency** of over 20 microseconds when working with small payload sizes (~10 bytes), which grows with the payload size up to over 10k microseconds with payloads of around 1 MB. The **throughput** is able to saturate a 1 GB/s network from over 1KB of payload in advance.

#### [4.3.4.5. Lab 2. Performance Evaluation](https://youtu.be/IyycN6ldsIs?t=6520)
This lab will be about evaluate DDS performance. Starting from a checked out clone of the [Cyclone DDS repository](https://github.com/eclipse-cyclonedds/cyclonedds) and building it with:

```bash
$ mkdir build
$ cd build
$ cmake ..
$ make
```

This will build a series of examples, throughout and latency tests and a DDS benchmarking tool (`ddsperf`). This benchmark can be used to run the throughout and latency tests. Once the general build is finished, all the executables will be located under the `/bin` directory, so the benchmark can be executed by running `./bin/ddsperf`, which will print some help on how to use the tool.

In order to perform a basic **throughout test**, a subscriber and a publisher are needed, which can be run by using `./bin/ddsperf sub` and `./bin/ddsperf pub size 1k` in other two terminals. The ammount of data received per second will be printed (amongst other statistics) in the subscriber terminal.

To run a **latency test**, the commands to be executed in each terminal are `./bin/ddsperf pong` and `./bin/ddsperf ping`. Again, statistics will be printed in each command prompt.

On [this page](https://index.ros.org/doc/ros2/Concepts/DDS-and-ROS-middleware-implementations/) there is information about how to choose Cyclone DDS (or other) as the default DDS implementation.


